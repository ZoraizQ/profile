{
  "name": "Zoraiz Qureshi",
  "title": "Charlottesville, VA, USA",
  "location": "Charlottesville, VA, 22903, United States",
  "email": "zoraizq@virginia.edu",
  "linkedin": "https://www.linkedin.com/in/zoraiz-qureshi/",
  "github": "https://github.com/ZoraizQ",
  "resume": "https://zoraizq.github.io/resume.pdf",
  "education": [
    {
      "role": "MS Computer Science",
      "place": "University of Virginia",
      "time": "Aug 2021 - Present"
    },
    {
      "role": "BS Computer Science",
      "place": "Lahore University of Management Sciences",
      "time": "2017 - 2021"
    }
  ],
  "experience": [
    {
      "role": "Research Assistant",
      "place": "University of Virginia",
      "time": "Aug 2021 - Present",
      "description": "Automation of the blood input function derivation pipeline using dynamic 18F-FDG PET images obtained from rodents and human subjects using machine learning and image analysis, under the supervision of Dr. Bijoy Kundu (Ph.D. Associate Professor of Radiology and Medical Imaging)."
    },
    {
      "role": "Teaching Assistant - CS315 Theory of Automata",
      "place": "Lahore University of Management Sciences",
      "time": "Jan 2021 - May 2021",
      "description": "For the course CS315 Theory of Automata instructed by Dr. Muhammad Hamad Alizai. Designed and evaluated a project based on development of a custom YAPL interpreter using PLY and knowledge of FSMs and CFGs."
    },
    {
      "role": "Teaching Assistant - CS452 Computer Graphics",
      "place": "Lahore University of Management Sciences",
      "time": "Jan 2021 – May 2021",
      "description": "For the course CS452 Computer Graphics instructed by Dr. Murtaza Taj. Designed and evaluated a multi-phase project on animation and game design through Blender, Unity and Unreal Engine. Conducted live virtual lab sessions on rasterization, mesh editing, raytracing, cloth simulation and other core topics."
    },
    {
      "role": "Application Developer",
      "place": "LIT - Learn Interact Think",
      "time": "May 2019 - Aug 2019",
      "description": "Developed an AR educational mobile app for iOS and Android developed using Unity3D for the Plan 9 startup Learn Interact Think, focusing on interactive 3D projections from custom bilingual storybooks based on the history and culture of Pakistan, with automated and dynamic user preference-based server-side generation integrated with order processing."
    }
  ],
  "projects": [
    {
      "title": "PhysCov - Quantifying Physical Coverage for Autonomous Drones (Microsoft AirSim)",
      "time": "Nov 2021 - Dec 2021",
      "description": "Thorough testing of autonomous systems for UAVs before their deployment is crucial to guarantee safety and mitigate costly failures. Existing software testing coverage metrics lack interpretability and these test adequacy metrics are not effective for complex AI driven autonomous vehicles. We extend PhysCov, a new physical coverage metric for autonomous vehicles, to the domain of UAVs - to measure coverage on a Software-In-The-Loop simulation tool like Microsoft AirSim.",
      "long_description": "Thorough testing of autonomous systems for UAVs before their deployment is crucial to guarantee safety and mitigate costly failures. Existing software testing coverage metrics lack interpretability and these test adequacy metrics are not effective for complex AI driven autonomous vehicles. We extend PhysCov, a new physical coverage metric for autonomous vehicles, to the domain of UAVs - to measure coverage on a Software-In-The-Loop simulation tool like Microsoft AirSim. This work is an extension of the original coverage metric proposed by Carl Hildebrandt (PhD Computer Science Student, UVA) under the supervision of Dr. Sebastian Elbaum (Professor Computer Science, UVA). Along with integration for real-time coverage measurements, we test various scenarios in AirSim using a quadrotor equipped with a LIDAR sensor under certain defined survey tasks. Based on our evaluation, we propose that gathering high coverage with PhysCov indicates testing of an adequate number of distinct behaviors for an autonomous flying system, uncovering potential failures such as collisions.",
      "link": "https://github.com/ZoraizQ/physcov_airsim_drone",
      "img": "https://github.com/ZoraizQ/physcov_airsim_drone/blob/master/assets/params.png?raw=true"
    },
    {
      "title": "GA-ANFIS and CRNN for Mental Attention State Classification using Passive BCI-based EEG data",
      "time": "Feb 2021 – May 2021",
      "description": "Detection and classification of human mental attention state for applications such as detecting driver fatigue and classroom focus. The state was divided into focused, unfocused and drowsy categories using electroencephalography (EEG) based BCI intrinsic activity data generated by specified individuals under live simulation (external dataset).",
      "long_description": "Detection and classification of human mental attention state for applications such as detecting driver fatigue and classroom focus. The state was divided into focused, unfocused and drowsy categories using electroencephalography (EEG) based BCI intrinsic activity data generated by specified individuals under live simulation (external dataset).",
      "link": "https://github.com/ZoraizQ/brain_mas_classifier",
      "img": "https://www.mydr.com.au/wp-content/uploads/2019/04/electroencephalogram_eeg.jpg"
    },
    {
      "title": "Semantic segmentation toolbox for image volumes using semi-automated annotation and deep learning",
      "time": "Sep 2020 – May 2021",
      "description": "A semi-automated annotation toolbox with 3D cross-sectional painting and interactive visualization to generate segmentation masks from TIFF image volumes, with live semantic segmentation using a custom UNET trained on neuron morphologies obtained from wide-field microscopy.",
      "long_description": "A semi-automated annotation toolbox with 3D cross-sectional painting and interactive visualization to generate segmentation masks from volumes of neuron morphologies obtained from wide-field microscopy. Further integrated a custom UNET based 2D convolutional neural network using Keras with both local and server-based prediction modes within the toolbox to enable live semantic segmentation.",
      "link": "https://github.com/ZoraizQ/annot3d",
      "img": "https://github.com/ZoraizQ/annot3d/raw/v0.3-pyqt5/graphics/pyside2_gui.jpg"
    },
    {
      "title": "Misinformation amid COVID-19: Investigating people’s susceptibility and perception",
      "time": "Jul 2020 – Feb 2021",
      "description": "Analyzed people’s susceptibilities to misinformation and their perceptions in the wake of the COVID-19 outbreak with a multidisciplinary team in collaboration with the University of Oxford and the Technology for People Initiative Lab, Lahore University of Management Sciences.",
      "long_description": "Analyzed people’s susceptibilities to misinformation and their perceptions in the wake of the COVID-19 outbreak with a multidisciplinary team in collaboration with the University of Oxford and the Technology for People Initiative Lab, Lahore University of Management Sciences, under the supervision of Dr. Fareed Zaffar (Ph.D. Duke), Dr. Zartash Uzmi (Ph.D. Stanford), Priya Sajjad (Ph.D. candidate, Oxford). The challenge was to add a new cultural and socio-economic perspective to research into what is driving the \"fake news\" phenomenon, and to situate it in the historical and socio-technical context of Pakistan by considering the country’s culturally unique aspects.",
      "img": "https://assets.medpagetoday.net/media/images/91xxx/91296.jpg"
    },
    {
      "title": "Madadgaar",
      "time": "Jun 2020 – Sep 2020",
      "description": "A complete blood donation system for donors to sign up and get notified about submitted blood requests from organizations/anonymous users via compatibility-based emails, SMS and in-app notifications while maintaining donor privacy. LUMS Students as Co-Researchers (ScR) Program 2020 Grant received.",
      "long_description": "A complete blood donation system for donors to sign up and get notified about submitted blood requests from organizations/anonymous users via compatibility-based emails, SMS and in-app notifications while maintaining donor privacy. LUMS Students as Co-Researchers (ScR) Program 2020 Grant received for 10 weeks from the Office of Research (OR) and LUMS Learning Institute (LLI), with Dr. Suleman Shahid as our faculty mentor.",
      "link": "https://madagaar-fba66.web.app/",
      "img": "https://i.imgur.com/M4610rF.png"
    },
    {
      "title": "PianoTunesAR",
      "time": "Jul 2020",
      "description": "[Wallifornia Hackathon 2020 - 1st Place Winning Team: 1,000 € MusicTech] Use AR to project your favorite digitally-recorded piano video song from YouTube over your piano to learn by following along. Built in C# with Unity and EasyAR.",
      "long_description": "[Wallifornia Hackathon 2020 - 1st Place Winning Team: 1,000 € MusicTech] Use AR to project your favorite digitally-recorded piano video song from YouTube over your piano to learn by following along. Built in C# with Unity and EasyAR.",
      "link": "https://devpost.com/software/pianotunesar",
      "img": "https://challengepost-s3-challengepost.netdna-ssl.com/photos/production/software_photos/001/147/132/datas/original.jpeg"
    },
    {
      "title": "Save Our Soul",
      "time": "Apr 2020 – Jun 2020",
      "description": "[COVID-19 Global Hackathon 2.0: Social & Mental Health Submission] Save Our Soul is an anonymous video and chat web application developed for people seeking mental help can anonymously connect with others seeking help or willing to provide help, along with advanced reporting.",
      "long_description": "[COVID-19 Global Hackathon 2.0: Social & Mental Health Submission] Save Our Soul is an anonymous video and chat web application developed for people seeking mental help can anonymously connect with others seeking help or willing to provide help, along with advanced reporting.",
      "link": "https://devpost.com/software/save-our-soul-quo1pn",
      "img": "https://camo.githubusercontent.com/7d601fc36010b5adf5ebe43c08bea99c86424eae02b6f74441372b4136f8384c/68747470733a2f2f6368616c6c656e6765706f73742d73332d6368616c6c656e6765706f73742e6e6574646e612d73736c2e636f6d2f70686f746f732f70726f64756374696f6e2f736f6674776172655f70686f746f732f3030312f3135312f3539332f64617461732f67616c6c6572792e6a7067"
    },
    {
      "title": "AgriScan",
      "time": "Mar 2020",
      "description": "[IEEE LUMS CodinGuru 2020 - Hackathon Winner] (hosted by Facebook Developer Circles) Deep Learning based Web App for Detection of Plant Diseases (SDG #2) Chat application that replies to a picture of a plant leaf and predicts using a pre-trained model whether it has the Leaf Curl VIrus (TYLCV), marking diseased locations for display.",
      "long_description": "[IEEE LUMS CodinGuru 2020 - Hackathon Winner] (hosted by Facebook Developer Circles) Deep Learning based Web App for Detection of Plant Diseases (SDG #2) Chat application that replies to a picture of a plant leaf and predicts using a pre-trained model whether it has the Leaf Curl VIrus (TYLCV), marking diseased locations for display.",
      "link": "https://devpost.com/software/hackathon-6gkwix",
      "img": "https://github.com/ZoraizQ/agriscan/raw/master/screenshots/SpiderMites.png"
    },
    {
      "title": "Co-Curricular Activities Management System",
      "time": "Apr 2020 – Jun 2020",
      "description": "Complex web application built for the Co-Curricular Activities Office at Lahore University of Management Sciences, featuring a Task Manager, a Form Maker / Viewer, advanced Admin settings, a Request Panel for monitoring submitted requests and a Society dashboard for submitting forms.",
      "long_description": "Complex web application using the MERN stack along with Redux and Material UI. Built for the Co-Curricular Activities Office at Lahore University of Management Sciences, featuring a completely customisable Task Manager with 2 types of tasks, a Form Maker with logical components, advanced Admin settings, a Request Panel for monitoring submitted requests, a Form Viewer, and a Society dashboard for submitting forms, all the components being highly interconnected through certain features.",
      "link": "https://drive.google.com/file/d/15sXAW-AgsbtQb-sAtEeFBlGa_ncdybuQ/view?usp=sharing",
      "img": "https://i.imgur.com/ybJs5Sc.png"
    },
    {
      "title": "SafarNama: Gamified Educational Virtual Touring for Pakistan",
      "time": "Jul 2020",
      "description": "Given the traditional teaching methods and lack of educational physical trips amid the COVID-19 pandemic, technology in education can be used as a solution to influence and motivate students to learn actively. For this purpose, we present SafarNama: a mobile Augmented Reality application with a novel approach to learning history and culture for Pakistan through gamified virtual trips using historically relevant 3D exhibits and an event-based dialogue system. The application aims to promote story-based, interactive and spatial learning as well as parental and teacher involvement and physical activity for children as they engage on virtual tours.",
      "long_description": "Given the traditional teaching methods and lack of educational physical trips amid the COVID-19 pandemic, technology in education can be used as a solution to influence and motivate students to learn actively. For this purpose, after a thorough user research and design prototyping process, we present SafarNama: a mobile Augmented Reality application with a novel approach to learning history and culture for Pakistan through gamified virtual trips using historically relevant 3D exhibits and an event-based dialogue system. With its unique design, the application aims to promote story-based, interactive and spatial learning as well as parental and teacher involvement and physical activity for children as they engage on virtual tours. We further analyze and review our design solution through an extensive user evaluation phase to determine its impact and implications for future research.",
      "link": "https://drive.google.com/file/d/18yr_Bmii4lxhLZcNgRa9FL_sL9e0CZIp/view?usp=sharing",
      "img": "https://i.imgur.com/l3JvS3I.png"
    },
    {
      "title": "WalkAR",
      "time": "Sep 2021 - Dec 2021",
      "description": "Using a physical map or a mobile navigation application for directions is a dull and single-minded experience, and the interfaces they provide do not naturally integrate into our surroundings. We present WalkAR - an Augmented Reality (AR) based navigation system focused on making on-foot navigation more enjoyable and educational using the elements of immersion, active learning and gamification combined with interactive and dynamic AR visualizations such as a virtual tour guide.",
      "long_description": "Using a physical map or a mobile navigation application for directions is a dull and single-minded experience, and sometimes we still get lost because of the complicated instructions as the interfaces they provide do not naturally integrate into our surroundings as perfectly. We present WalkAR - an Augmented Reality (AR) based navigation system focused on making on-foot navigation more enjoyable and educational using the elements of immersion, active learning and gamification combined with interactive and dynamic AR visualizations such as a virtual tour guide.  We design and evaluate the system in the context of a tour set out for new students visiting the University of Virginia campus, demonstrating the capabilities of its distinct features for enhancing the navigation experience in circumstances where time is sufficient and users yearn to tour along the way to their destination.",
      "link": "https://drive.google.com/file/d/1SB5K0F3cWq3dSJdaog4WmHM3x-HHyncX/view?usp=sharing",
      "img": "https://i.imgur.com/cdwXGDO.png"
    }
  ]
}